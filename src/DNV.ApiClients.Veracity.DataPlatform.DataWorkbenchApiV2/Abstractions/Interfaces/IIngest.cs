// <auto-generated>
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace DNV.ApiClients.Veracity.DataPlatform.DataWorkbenchApiV2.Interfaces
{
    using Microsoft.Rest;
    using Models;
    using System.Collections;
    using System.Collections.Generic;
    using System.Threading;
    using System.Threading.Tasks;

    /// <summary>
    /// Ingest operations.
    /// </summary>
    public partial interface IIngest
    {
        /// <summary>
        /// Get data ingest endpoint for current workspace
        /// </summary>
        /// <remarks>
        /// Sample request
        ///
        /// dfs:
        /// POST {workspaceId}/Ingest?type=dfs
        /// POST
        /// {workspaceId}/Ingest?datasetId=be072260-78d9-4e14-ac16-942284026577&amp;type=dfs
        /// blob:
        /// POST {workspaceId}/Ingest?type=blob
        /// POST
        /// {workspaceId}/Ingest?datasetId=be072260-78d9-4e14-ac16-942284026577&amp;type=blob
        ///
        /// Sample response
        ///
        /// dfs:
        /// https://{domain}.dfs.core.windows.net/196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86/a16d1d0d-2b92-4e71-b2a1-2931ce61c863/Raw?sv=2023-11-03&amp;spr=https&amp;st=2024-07-12T01%3A55%3A12Z&amp;se=2024-07-12T02%3A10%3A12Z&amp;sr=d&amp;sp=cw&amp;sdd=2&amp;sig=%2BaxD8B250vI0bJn9u8KHRv7duvLjqXlhOfVBOCi5Cqo%3D
        /// blob:
        /// https://{domain}.blob.core.windows.net/196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86/f5a0ef4c-e76f-4d1c-9b0d-947c8b7923ff/Raw?sv=2023-11-03&amp;spr=https&amp;st=2024-07-12T01%3A56%3A01Z&amp;se=2024-07-12T02%3A11%3A01Z&amp;sr=d&amp;sp=cw&amp;sdd=2&amp;sig=EzfaySpQ5hAN2eLEAPp4vhRIyvMUDikD4iFKDmagpKM%3D
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='type'>
        /// Possible values include: 'dfs', 'blob'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        [System.Obsolete("This operation is deprecated. Please do not use it any longer.")]
        Task<HttpOperationResponse<string>> GenerateByodStorageWithHttpMessagesAsync(System.Guid workspaceId, System.Guid? datasetId = default, string type = default, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get data ingest endpoint for current workspace
        /// </summary>
        /// <remarks>
        /// Sample request
        ///
        /// dfs:
        /// POST {workspaceId}/Ingest?type=dfs
        /// POST
        /// {workspaceId}/Ingest?datasetId=be072260-78d9-4e14-ac16-942284026577&amp;type=dfs
        /// blob:
        /// POST {workspaceId}/Ingest?type=blob
        /// POST
        /// {workspaceId}/Ingest?datasetId=be072260-78d9-4e14-ac16-942284026577&amp;type=blob
        ///
        /// Sample response
        ///
        /// dfs:
        /// https://{domain}.dfs.core.windows.net/196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86/a16d1d0d-2b92-4e71-b2a1-2931ce61c863/Raw?sv=2023-11-03&amp;spr=https&amp;st=2024-07-12T01%3A55%3A12Z&amp;se=2024-07-12T02%3A10%3A12Z&amp;sr=d&amp;sp=cw&amp;sdd=2&amp;sig=%2BaxD8B250vI0bJn9u8KHRv7duvLjqXlhOfVBOCi5Cqo%3D
        /// blob:
        /// https://{domain}.blob.core.windows.net/196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86/f5a0ef4c-e76f-4d1c-9b0d-947c8b7923ff/Raw?sv=2023-11-03&amp;spr=https&amp;st=2024-07-12T01%3A56%3A01Z&amp;se=2024-07-12T02%3A11%3A01Z&amp;sr=d&amp;sp=cw&amp;sdd=2&amp;sig=EzfaySpQ5hAN2eLEAPp4vhRIyvMUDikD4iFKDmagpKM%3D
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='type'>
        /// Possible values include: 'dfs', 'blob'
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        [System.Obsolete("This operation is deprecated. Please do not use it any longer.")]
        Task<string> GenerateByodStorageAsync(System.Guid workspaceId, System.Guid? datasetId = default, string type = default, CancellationToken cancellationToken = default);

        /// <summary>
        /// Create an ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample request For Create Ingest Dataset:
        ///
        /// {
        /// "datasetName": "string",
        /// "datasetDescription": "string",
        /// "schemaVersionId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "files": [
        /// {
        /// "fileName": "string",
        /// "operation": "Create"
        /// }
        /// ],
        /// "tags": [
        /// {
        /// "key": "tag1",
        /// "values": [
        /// "tag1Value"
        /// ]
        /// },
        /// {
        /// "key": "tag2",
        /// "values": [
        /// "tag2Value"
        /// ]
        /// }
        /// ],
        /// "provider": "string",
        /// "startAutomatically": true
        /// }
        ///
        /// * startAutomatically is optional with default value as true.
        /// If set to true, the file will be processed automatically. (There is
        /// no need to run the validate and start endpoint manually after
        /// uploading the file).
        /// If set to false, please call the validate and start endpoint
        /// manually after uploading the file.
        /// * tags are optional. Either send null, or an array with at least 1
        /// tag.
        /// * provider is optional and should only be specified if you have
        /// been informed to do so.
        ///
        /// Sample Response:
        ///
        /// {
        /// "workspaceId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "sasToken": "string"
        /// }
        ///
        /// * jobId in the response is the ingest job which will take care of
        /// creating the ingest dataset.
        /// * sasToken in the response is the token which will be used to
        /// upload the file to create ingest dataset.
        /// </remarks>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        /// <exception cref="Microsoft.Rest.ValidationException">
        /// Thrown when a required parameter is null
        /// </exception>
        Task<HttpOperationResponse<IngestDatasetResponseDTO>> CreateIngestDatasetWithHttpMessagesAsync(CreateIngestDatasetRequestDTO body, System.Guid workspaceId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Create an ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample request For Create Ingest Dataset:
        ///
        /// {
        /// "datasetName": "string",
        /// "datasetDescription": "string",
        /// "schemaVersionId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "files": [
        /// {
        /// "fileName": "string",
        /// "operation": "Create"
        /// }
        /// ],
        /// "tags": [
        /// {
        /// "key": "tag1",
        /// "values": [
        /// "tag1Value"
        /// ]
        /// },
        /// {
        /// "key": "tag2",
        /// "values": [
        /// "tag2Value"
        /// ]
        /// }
        /// ],
        /// "provider": "string",
        /// "startAutomatically": true
        /// }
        ///
        /// * startAutomatically is optional with default value as true.
        /// If set to true, the file will be processed automatically. (There is
        /// no need to run the validate and start endpoint manually after
        /// uploading the file).
        /// If set to false, please call the validate and start endpoint
        /// manually after uploading the file.
        /// * tags are optional. Either send null, or an array with at least 1
        /// tag.
        /// * provider is optional and should only be specified if you have
        /// been informed to do so.
        ///
        /// Sample Response:
        ///
        /// {
        /// "workspaceId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "sasToken": "string"
        /// }
        ///
        /// * jobId in the response is the ingest job which will take care of
        /// creating the ingest dataset.
        /// * sasToken in the response is the token which will be used to
        /// upload the file to create ingest dataset.
        /// </remarks>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<IngestDatasetResponseDTO> CreateIngestDatasetAsync(CreateIngestDatasetRequestDTO body, System.Guid workspaceId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Update an existing dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample request For Updating Ingest Dataset:
        ///
        /// {
        /// "files": [
        /// {
        /// "fileName": "string",
        /// "operation": "Upsert"
        /// }
        /// ]
        /// "startAutomatically": true,
        /// "datasetDescription": "string",
        /// "tags": [
        /// {
        /// "key": "tag1",
        /// "values": [
        /// "tag1Value"
        /// ]
        /// },
        /// {
        /// "key": "tag2",
        /// "values": [
        /// "tag2Value"
        /// ]
        /// }
        /// ]
        /// }
        ///
        /// * startAutomatically is optional with default value as true.
        /// If set to true, there is no need to call the validate and start
        /// endpoint manually after uploading the file.
        /// If set to false, we should run the validate and start endpoint
        /// manually after uploading the file.
        /// * datasetDescription is optional.
        /// * tags are optional. Either send null, or an array with at least 1
        /// tag.
        ///
        /// Sample Response:
        ///
        /// {
        /// "workspaceId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "sasToken": "string"
        /// }
        ///
        /// * jobId in the response is the ingest job which will take care of
        /// updating the ingest dataset.
        /// * sasToken in the response is the token which will be used to
        /// upload the file to update ingest dataset
        /// </remarks>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        /// <exception cref="Microsoft.Rest.ValidationException">
        /// Thrown when a required parameter is null
        /// </exception>
        Task<HttpOperationResponse<IngestDatasetResponseDTO>> UpdateIngestDatasetWithHttpMessagesAsync(UpdateIngestDatasetRequestDTO body, System.Guid workspaceId, System.Guid datasetId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Update an existing dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample request For Updating Ingest Dataset:
        ///
        /// {
        /// "files": [
        /// {
        /// "fileName": "string",
        /// "operation": "Upsert"
        /// }
        /// ]
        /// "startAutomatically": true,
        /// "datasetDescription": "string",
        /// "tags": [
        /// {
        /// "key": "tag1",
        /// "values": [
        /// "tag1Value"
        /// ]
        /// },
        /// {
        /// "key": "tag2",
        /// "values": [
        /// "tag2Value"
        /// ]
        /// }
        /// ]
        /// }
        ///
        /// * startAutomatically is optional with default value as true.
        /// If set to true, there is no need to call the validate and start
        /// endpoint manually after uploading the file.
        /// If set to false, we should run the validate and start endpoint
        /// manually after uploading the file.
        /// * datasetDescription is optional.
        /// * tags are optional. Either send null, or an array with at least 1
        /// tag.
        ///
        /// Sample Response:
        ///
        /// {
        /// "workspaceId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "sasToken": "string"
        /// }
        ///
        /// * jobId in the response is the ingest job which will take care of
        /// updating the ingest dataset.
        /// * sasToken in the response is the token which will be used to
        /// upload the file to update ingest dataset
        /// </remarks>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<IngestDatasetResponseDTO> UpdateIngestDatasetAsync(UpdateIngestDatasetRequestDTO body, System.Guid workspaceId, System.Guid datasetId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Ingest Job History for Dataset
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// result: [
        /// {
        /// "jobId": "26a39ea0-0702-4d07-8170-171f50388f83",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-22T18:18:52.4399275Z",
        /// "createdBy": "1346ea17-6954-4e46-9c8d-a56bb9dc76d1",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "An unexpected error occurred. Please contact support.",
        /// "notebookError": "",
        /// "validationError": [],
        /// "lastModifiedAt": "2025-04-22T18:24:09.9343922Z"
        /// },
        /// {
        /// "jobId": "69b41efe-4988-4db5-a0da-4798bc9f3bf3",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "datasetId": "f0a29868-b286-4605-9d4b-7a31479dab3d",
        /// "createdAt": "2025-06-03T09:12:33.3609211Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Completed",
        /// "operations": [
        /// "Upsert"
        /// ],
        /// "notebookError": "",
        /// "lastModifiedAt": "2025-06-03T09:16:27.584353Z"
        /// },
        /// {
        /// "jobId": "14bc90e8-f107-479c-8a4b-6ecb91593986",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-05-13T21:20:22.5283497Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "File(s) failed to validate.",
        /// "notebookError": "",
        /// "validationError": [
        /// {
        /// "fileName": "Upload.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Missing columns: IMO,
        /// Vessel_Name, Voyage_Id, Leg_Start_DateTime, Leg_End_DateTime,
        /// Leg_Mode, Port_From_Code, Port_From_Name, Port_To_Code,
        /// Port_To_Name, Hours_Underway, Total_Reported_Time,
        /// Transport_Work_PP, Transport_Work_Unit_PP, Transport_Work,
        /// Transport_Work_Unit, CO2_Emitted_Mt, Distance, Cargo_Mt, Cargo_M3,
        /// Cargo_Pax, Cargo_TEU, Deadweight, Gross_Tonnage, Cargo_Percentage,
        /// Vessel_Flag, Vessel_Type_DCS, Vessel_Type_PP, Vessel_Type_Other,
        /// Vessel_Category_PP, Data_Classification, AIS_Distance,
        /// AIS_Duration, AIS_CO2_Emitted. Extra columns: ID, TS, NodeID,
        /// Signal, Value."
        /// }
        /// ],
        /// "lastModifiedAt": "2025-05-13T21:23:15.9390815Z"
        /// }
        /// ],
        /// "pageIndex": 1,
        /// "pageSize": 10,
        /// "totalCount": 43,
        /// "totalPages": 5
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='pageIndex'>
        /// </param>
        /// <param name='pageSize'>
        /// </param>
        /// <param name='sortColumn'>
        /// </param>
        /// <param name='sortDirection'>
        /// Possible values include: 'Ascending', 'Descending'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        Task<HttpOperationResponse<JobHistoryDTOPaginatedResult>> GetDatasetJobHistoryWithHttpMessagesAsync(System.Guid workspaceId, System.Guid datasetId, int? pageIndex = default, int? pageSize = default, string sortColumn = default, string sortDirection = default, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Ingest Job History for Dataset
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// result: [
        /// {
        /// "jobId": "26a39ea0-0702-4d07-8170-171f50388f83",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-22T18:18:52.4399275Z",
        /// "createdBy": "1346ea17-6954-4e46-9c8d-a56bb9dc76d1",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "An unexpected error occurred. Please contact support.",
        /// "notebookError": "",
        /// "validationError": [],
        /// "lastModifiedAt": "2025-04-22T18:24:09.9343922Z"
        /// },
        /// {
        /// "jobId": "69b41efe-4988-4db5-a0da-4798bc9f3bf3",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "datasetId": "f0a29868-b286-4605-9d4b-7a31479dab3d",
        /// "createdAt": "2025-06-03T09:12:33.3609211Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Completed",
        /// "operations": [
        /// "Upsert"
        /// ],
        /// "notebookError": "",
        /// "lastModifiedAt": "2025-06-03T09:16:27.584353Z"
        /// },
        /// {
        /// "jobId": "14bc90e8-f107-479c-8a4b-6ecb91593986",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-05-13T21:20:22.5283497Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "File(s) failed to validate.",
        /// "notebookError": "",
        /// "validationError": [
        /// {
        /// "fileName": "Upload.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Missing columns: IMO,
        /// Vessel_Name, Voyage_Id, Leg_Start_DateTime, Leg_End_DateTime,
        /// Leg_Mode, Port_From_Code, Port_From_Name, Port_To_Code,
        /// Port_To_Name, Hours_Underway, Total_Reported_Time,
        /// Transport_Work_PP, Transport_Work_Unit_PP, Transport_Work,
        /// Transport_Work_Unit, CO2_Emitted_Mt, Distance, Cargo_Mt, Cargo_M3,
        /// Cargo_Pax, Cargo_TEU, Deadweight, Gross_Tonnage, Cargo_Percentage,
        /// Vessel_Flag, Vessel_Type_DCS, Vessel_Type_PP, Vessel_Type_Other,
        /// Vessel_Category_PP, Data_Classification, AIS_Distance,
        /// AIS_Duration, AIS_CO2_Emitted. Extra columns: ID, TS, NodeID,
        /// Signal, Value."
        /// }
        /// ],
        /// "lastModifiedAt": "2025-05-13T21:23:15.9390815Z"
        /// }
        /// ],
        /// "pageIndex": 1,
        /// "pageSize": 10,
        /// "totalCount": 43,
        /// "totalPages": 5
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='datasetId'>
        /// </param>
        /// <param name='pageIndex'>
        /// </param>
        /// <param name='pageSize'>
        /// </param>
        /// <param name='sortColumn'>
        /// </param>
        /// <param name='sortDirection'>
        /// Possible values include: 'Ascending', 'Descending'
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<JobHistoryDTOPaginatedResult> GetDatasetJobHistoryAsync(System.Guid workspaceId, System.Guid datasetId, int? pageIndex = default, int? pageSize = default, string sortColumn = default, string sortDirection = default, CancellationToken cancellationToken = default);

        /// <summary>
        /// Import a dataset to the workspace
        /// </summary>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        /// <exception cref="Microsoft.Rest.ValidationException">
        /// Thrown when a required parameter is null
        /// </exception>
        Task<HttpOperationResponse<DataCatalogReadDtoV2>> ImportDatasetWithHttpMessagesAsync(ImportDatasetDTO body, System.Guid workspaceId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Import a dataset to the workspace
        /// </summary>
        /// <param name='body'>
        /// </param>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<DataCatalogReadDtoV2> ImportDatasetAsync(ImportDatasetDTO body, System.Guid workspaceId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Start an existing job for ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample Response:
        ///
        /// {
        /// "startJobStatus": "JobNotFound",
        /// "isValid": true,
        /// "validationResponse": {
        /// "errorReason": "string",
        /// "files": {
        /// "additionalProp1": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp2": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp3": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// }
        /// }
        /// }
        /// }
        ///
        /// * If the validation for job or files fail, the response will have
        /// validation errors and job will not start.
        /// * If validation is successfull, the response will not have any
        /// validation error and job will start.
        /// * If job was set to startAutomatically = true, job will not start
        /// as it was set to start automatically.
        /// * If job has already started, job will not start again.
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        Task<HttpOperationResponse<StartJobResultDTO>> StartIngestJobWithHttpMessagesAsync(System.Guid workspaceId, System.Guid jobId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Start an existing job for ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample Response:
        ///
        /// {
        /// "startJobStatus": "JobNotFound",
        /// "isValid": true,
        /// "validationResponse": {
        /// "errorReason": "string",
        /// "files": {
        /// "additionalProp1": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp2": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp3": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// }
        /// }
        /// }
        /// }
        ///
        /// * If the validation for job or files fail, the response will have
        /// validation errors and job will not start.
        /// * If validation is successfull, the response will not have any
        /// validation error and job will start.
        /// * If job was set to startAutomatically = true, job will not start
        /// as it was set to start automatically.
        /// * If job has already started, job will not start again.
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<StartJobResultDTO> StartIngestJobAsync(System.Guid workspaceId, System.Guid jobId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get status of an ingest job
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "errorMessage": "Databricks processing error.",
        /// "notebookErrorMessage": "Failed to execute CREATE operation.",
        /// "validationError": []
        /// }
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Completed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "notebookErrorMessage": "",
        /// "dataSetName": "datasetName",
        /// "datasetId": "3fa85f64-5717-4562-b3fc-2c963f66afa6"
        /// }
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "errorMessage": "File(s) failed to validate.",
        /// "notebookErrorMessage": "",
        /// "validationError": [
        /// {
        /// "FileName": "test.csv",
        /// "isValid": false,
        /// "errorReason": "File not found."
        /// }
        /// {
        /// "FileName": "test.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Extra columns:
        /// Weight."
        /// }
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        Task<HttpOperationResponse<JobStatusDTO>> GetIngestJobStatusWithHttpMessagesAsync(System.Guid workspaceId, System.Guid jobId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get status of an ingest job
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "errorMessage": "Databricks processing error.",
        /// "notebookErrorMessage": "Failed to execute CREATE operation.",
        /// "validationError": []
        /// }
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Completed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "notebookErrorMessage": "",
        /// "dataSetName": "datasetName",
        /// "datasetId": "3fa85f64-5717-4562-b3fc-2c963f66afa6"
        /// }
        ///
        /// {
        /// "jobId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "errorMessage": "File(s) failed to validate.",
        /// "notebookErrorMessage": "",
        /// "validationError": [
        /// {
        /// "FileName": "test.csv",
        /// "isValid": false,
        /// "errorReason": "File not found."
        /// }
        /// {
        /// "FileName": "test.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Extra columns:
        /// Weight."
        /// }
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<JobStatusDTO> GetIngestJobStatusAsync(System.Guid workspaceId, System.Guid jobId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Validate an existing job for ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample Response:
        ///
        /// {
        /// "isValid": true,
        /// "errorReason": "string",
        /// "files": {
        /// "additionalProp1": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp2": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp3": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// }
        /// }
        /// }
        /// }
        ///
        /// * If job is set to startAutomatically = true, validation will not
        /// happen.
        /// * response will show the validation result for all files regardless
        /// they are valid or invalid.
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        Task<HttpOperationResponse<JobValidationResultDTO>> ValidateIngestJobWithHttpMessagesAsync(System.Guid workspaceId, System.Guid jobId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Validate an existing job for ingest dataset in the workspace
        /// </summary>
        /// <remarks>
        /// Sample Response:
        ///
        /// {
        /// "isValid": true,
        /// "errorReason": "string",
        /// "files": {
        /// "additionalProp1": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp2": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// },
        /// "additionalProp3": {
        /// "isValid": true,
        /// "errorReason": "string"
        /// }
        /// }
        /// }
        /// }
        ///
        /// * If job is set to startAutomatically = true, validation will not
        /// happen.
        /// * response will show the validation result for all files regardless
        /// they are valid or invalid.
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='jobId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<JobValidationResultDTO> ValidateIngestJobAsync(System.Guid workspaceId, System.Guid jobId, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Ingest Job History for workspace
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// result: [
        /// {
        /// "jobId": "26a39ea0-0702-4d07-8170-171f50388f83",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-22T18:18:52.4399275Z",
        /// "createdBy": "1346ea17-6954-4e46-9c8d-a56bb9dc76d1",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "An unexpected error occurred. Please contact support.",
        /// "notebookError": "",
        /// "validationError": [],
        /// "lastModifiedAt": "2025-04-22T18:24:09.9343922Z"
        /// },
        /// {
        /// "jobId": "8bcc224b-96b7-4f54-99c3-5c62a7a0b5b1",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-30T16:00:01.8200722Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Proposed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "",
        /// "notebookError": "",
        /// "validationError": []
        /// },
        /// {
        /// "jobId": "14bc90e8-f107-479c-8a4b-6ecb91593986",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-05-13T21:20:22.5283497Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "File(s) failed to validate.",
        /// "notebookError": "",
        /// "validationError": [
        /// {
        /// "fileName": "Upload.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Missing columns: IMO,
        /// Vessel_Name, Voyage_Id, Leg_Start_DateTime, Leg_End_DateTime,
        /// Leg_Mode, Port_From_Code, Port_From_Name, Port_To_Code,
        /// Port_To_Name, Hours_Underway, Total_Reported_Time,
        /// Transport_Work_PP, Transport_Work_Unit_PP, Transport_Work,
        /// Transport_Work_Unit, CO2_Emitted_Mt, Distance, Cargo_Mt, Cargo_M3,
        /// Cargo_Pax, Cargo_TEU, Deadweight, Gross_Tonnage, Cargo_Percentage,
        /// Vessel_Flag, Vessel_Type_DCS, Vessel_Type_PP, Vessel_Type_Other,
        /// Vessel_Category_PP, Data_Classification, AIS_Distance,
        /// AIS_Duration, AIS_CO2_Emitted. Extra columns: ID, TS, NodeID,
        /// Signal, Value."
        /// }
        /// ],
        /// "lastModifiedAt": "2025-05-13T21:23:15.9390815Z"
        /// }
        /// ],
        /// "pageIndex": 1,
        /// "pageSize": 10,
        /// "totalCount": 43,
        /// "totalPages": 5
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='pageIndex'>
        /// </param>
        /// <param name='pageSize'>
        /// </param>
        /// <param name='sortColumn'>
        /// </param>
        /// <param name='sortDirection'>
        /// Possible values include: 'Ascending', 'Descending'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="Microsoft.Rest.HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="Microsoft.Rest.SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        Task<HttpOperationResponse<JobHistoryDTOPaginatedResult>> GetWorkspaceJobHistoryWithHttpMessagesAsync(System.Guid workspaceId, int? pageIndex = default, int? pageSize = default, string sortColumn = default, string sortDirection = default, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Ingest Job History for workspace
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// result: [
        /// {
        /// "jobId": "26a39ea0-0702-4d07-8170-171f50388f83",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-22T18:18:52.4399275Z",
        /// "createdBy": "1346ea17-6954-4e46-9c8d-a56bb9dc76d1",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "An unexpected error occurred. Please contact support.",
        /// "notebookError": "",
        /// "validationError": [],
        /// "lastModifiedAt": "2025-04-22T18:24:09.9343922Z"
        /// },
        /// {
        /// "jobId": "8bcc224b-96b7-4f54-99c3-5c62a7a0b5b1",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-04-30T16:00:01.8200722Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Proposed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "",
        /// "notebookError": "",
        /// "validationError": []
        /// },
        /// {
        /// "jobId": "14bc90e8-f107-479c-8a4b-6ecb91593986",
        /// "workspaceId": "196a8ff4-dfbc-4ee7-ae08-4f38b84d9c86",
        /// "createdAt": "2025-05-13T21:20:22.5283497Z",
        /// "createdBy": "00000000-0000-0000-0000-000000000001",
        /// "status": "Failed",
        /// "operations": [
        /// "Create"
        /// ],
        /// "error": "File(s) failed to validate.",
        /// "notebookError": "",
        /// "validationError": [
        /// {
        /// "fileName": "Upload.csv",
        /// "isValid": false,
        /// "errorReason": "Columns do not match schema. Missing columns: IMO,
        /// Vessel_Name, Voyage_Id, Leg_Start_DateTime, Leg_End_DateTime,
        /// Leg_Mode, Port_From_Code, Port_From_Name, Port_To_Code,
        /// Port_To_Name, Hours_Underway, Total_Reported_Time,
        /// Transport_Work_PP, Transport_Work_Unit_PP, Transport_Work,
        /// Transport_Work_Unit, CO2_Emitted_Mt, Distance, Cargo_Mt, Cargo_M3,
        /// Cargo_Pax, Cargo_TEU, Deadweight, Gross_Tonnage, Cargo_Percentage,
        /// Vessel_Flag, Vessel_Type_DCS, Vessel_Type_PP, Vessel_Type_Other,
        /// Vessel_Category_PP, Data_Classification, AIS_Distance,
        /// AIS_Duration, AIS_CO2_Emitted. Extra columns: ID, TS, NodeID,
        /// Signal, Value."
        /// }
        /// ],
        /// "lastModifiedAt": "2025-05-13T21:23:15.9390815Z"
        /// }
        /// ],
        /// "pageIndex": 1,
        /// "pageSize": 10,
        /// "totalCount": 43,
        /// "totalPages": 5
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='pageIndex'>
        /// </param>
        /// <param name='pageSize'>
        /// </param>
        /// <param name='sortColumn'>
        /// </param>
        /// <param name='sortDirection'>
        /// Possible values include: 'Ascending', 'Descending'
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<JobHistoryDTOPaginatedResult> GetWorkspaceJobHistoryAsync(System.Guid workspaceId, int? pageIndex = default, int? pageSize = default, string sortColumn = default, string sortDirection = default, CancellationToken cancellationToken = default);

        /// <summary>
        /// Retrieve the content of the BYOD status file
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// "status": "Started",
        /// "correlationId": "203bfa0b-86c3-4467-a3b0-d2eb415a96cc",
        /// "fileName": "TestUpload.csv"
        /// }
        ///
        /// {
        /// "status": "Completed",
        /// "correlationId": "203bfa0b-86c3-4467-a3b0-d2eb415a96cc",
        /// "fileName": "TestUpload.csv",
        /// "dataSetName": "TestUploadLILN"
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='requestId'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        /// <exception cref="HttpOperationException">
        /// Thrown when the operation returned an invalid status code
        /// </exception>
        /// <exception cref="SerializationException">
        /// Thrown when unable to deserialize the response
        /// </exception>
        [System.Obsolete("This operation is deprecated. Please do not use it any longer.")]
        Task<HttpOperationResponse<StatusLogModel>> GetStatusLogWithHttpMessagesAsync(System.Guid workspaceId, System.Guid requestId, Dictionary<string, IList<string>> customHeaders = null, CancellationToken cancellationToken = default);

        /// <summary>
        /// Retrieve the content of the BYOD status file
        /// </summary>
        /// <remarks>
        /// Sample Response
        ///
        /// {
        /// "status": "Started",
        /// "correlationId": "203bfa0b-86c3-4467-a3b0-d2eb415a96cc",
        /// "fileName": "TestUpload.csv"
        /// }
        ///
        /// {
        /// "status": "Completed",
        /// "correlationId": "203bfa0b-86c3-4467-a3b0-d2eb415a96cc",
        /// "fileName": "TestUpload.csv",
        /// "dataSetName": "TestUploadLILN"
        /// }
        /// </remarks>
        /// <param name='workspaceId'>
        /// </param>
        /// <param name='requestId'>
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        [System.Obsolete("This operation is deprecated. Please do not use it any longer.")]
        Task<StatusLogModel> GetStatusLogAsync(System.Guid workspaceId, System.Guid requestId, CancellationToken cancellationToken = default);

    }
}
